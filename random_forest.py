# -*- coding: utf-8 -*-
"""Random_Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gH0WHncOSb7YaU5AaoTv1IYTjoIOyYq0

#**Classification with Random Forest**

* This code uses the RandomForestClassifier class from the sklearn module to train a RandomForest classifier on the breast cancer dataset.

* The fit() method is used to train the classifier on the training data, and the predict() method is used to predict the class labels of the test data.

* The score() method is used to evaluate the accuracy of the classifier on the test data.

##**1. Import libraries**
"""

# Import important libraries
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

"""##**2. Load your dataset**

Breast cancer dataset: This dataset contains measurements of breast cancer cells, with the goal of classifying them as benign or malignant.
"""

from sklearn.datasets import load_breast_cancer

# Load the dataset
data_cancer = load_breast_cancer()

# Convert the features and target to a dataframe
Data_breast_cancer = pd.DataFrame(data_cancer .data, columns=data_cancer.feature_names)
Data_breast_cancer['target'] = pd.Series(data_cancer.target)

"""##**3. Visualised your dataset**"""

# Let view the first five rows of our data
Data_breast_cancer.head()

#Check if there a missing values
Data_breast_cancer.info()

# Check shape
Data_breast_cancer.shape

"""##**4. Sperate your data into independent (x) and dependent (y) variables**"""

#Independent variables (x)
X_variables = Data_breast_cancer.drop(["target"], axis=1)

#Dependent variable (y)
y_variable = Data_breast_cancer["target"]

# Scale the X_variable using MinMaxScaler
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
X_variables_scaled = scaler.fit_transform(X_variables)

"""##**5. Split your data into train and test**"""

# Split the data into training (75%) and testing sets (25%)
X_train, X_test, y_train, y_test = train_test_split(X_variables_scaled, y_variable, test_size=0.25, random_state=42)

"""##**6. Creat your model**"""

# Create a DecisionTreeClassifier object
RF_model = RandomForestClassifier(n_estimators=100, random_state=42)

"""##**7. Train (fit) your RF model**"""

# Train the classifier on the training data
RF_model.fit(X_train, y_train)

"""##**8. Test (Evaluate the performance) of your RF model**"""

# Predict the class labels of the test data
y_pred = RF_model.predict(X_test)

"""##**9. Check the eveluation metric of your model**

Let calculate the following metrics of our DT_model based on y_pred
 * accuracy,
 * recall,
 * precision,
 * F1-Score,
 * AUC,
 * confusion matrix
"""

from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix

print("Accuracy:", accuracy_score(y_test, y_pred))
print("Precision:", precision_score(y_test, y_pred))
print("Recall:", recall_score(y_test, y_pred))
print("F1 Score:", f1_score(y_test, y_pred))
print("AUC:", roc_auc_score(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))

from sklearn.metrics import roc_curve
import matplotlib.pyplot as plt

y_pred_prob = RF_model.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)

plt.plot(fpr, tpr, label='ROC Curve')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

"""## **10. Important feature**"""

importance = RF_model.feature_importances_
indices = np.argsort(importance)[::-1]
features = X_variables.columns

# Print the feature ranking
print("Feature ranking:")

for f in range(X_variables.shape[1]):
    print("%d. %s (%f)" % (f + 1, features[indices[f]], importance[indices[f]]))

importance = RF_model.feature_importances_
indices = np.argsort(importance)[::-1]
features = X_variables.columns

# Create a bar chart of feature importances
plt.figure()
plt.title("Feature importances")
plt.bar(range(X_variables.shape[1]), importance[indices],
        color="r", align="center")
plt.xticks(range(X_variables.shape[1]), features[indices], rotation=90)
plt.xlim([-1, X_variables.shape[1]])
plt.tight_layout()
plt.show()